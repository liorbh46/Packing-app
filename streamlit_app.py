import streamlit as st
import google.generativeai as genai

# --- 专转 注 ---
st.set_page_config(page_title="PackBot AI", page_icon="С", layout="centered")

# --- 注转 驻转 砖 ---
# 砖 :  砖驻专住转 转 驻转 , 抓 注转 拽 转 爪专 砖 .
# 转  注 注.
API_KEY = "AIzaSyC37M65UwKU3RuKXMb9W6TFCq7IB8yrGS8"

# --- 专转  ---
try:
    genai.configure(api_key=API_KEY)
    # 砖砖  Flash 专 注
    model = genai.GenerativeModel('gemini-1.5-flash')
except Exception as e:
    st.error(f"砖 专转 驻转: {e}")

# --- 注爪 ---
st.markdown("""
<style>
    .stChatMessage {direction: rtl; text-align: right;}
    .stChatInput {direction: rtl;}
    div[data-testid="stMarkdownContainer"] {text-align: right;}
    h1 {text-align: center;}
    .stButton button {width: 100%;}
</style>
""", unsafe_allow_html=True)

st.title("С PackBot AI")
st.caption("驻注 注\" Google Gemini")

# ---  专 砖 ---
if "messages" not in st.session_state:
    st.session_state.messages = [
        {"role": "model", "parts": ["!   专 砖.  住 转? 转 住驻爪驻  砖 转转 驻 注."]}
    ]

# --- 驻拽爪 驻  ---
def ask_gemini(prompt):
    try:
        # 爪专转 住专
        history = []
        for msg in st.session_state.messages[:-1]:
            role = "user" if msg["role"] == "user" else "model"
            history.append({"role": role, "parts": msg["parts"]})
            
        chat = model.start_chat(history=history)
        response = chat.send_message(prompt)
        return response.text
    except Exception as e:
        #  砖 砖, 住   砖 转专
        try:
            fallback_model = genai.GenerativeModel('gemini-pro')
            chat = fallback_model.start_chat(history=history)
            response = chat.send_message(prompt)
            return response.text
        except:
            return f"砖: {str(e)}.  砖驻转 转拽 砖拽抓 requirements.txt 注."

# --- 爪转 砖 ---
for msg in st.session_state.messages:
    role = "assistant" if msg["role"] == "model" else "user"
    st.chat_message(role).write(msg["parts"][0])

# --- 驻 拽 ---
if prompt := st.chat_input("转 ..."):
    # 爪转 注转 砖转砖
    st.chat_message("user").write(prompt)
    st.session_state.messages.append({"role": "user", "parts": [prompt]})

    # 拽转 转砖
    with st.spinner("砖..."):
        ai_response = ask_gemini(prompt)

    # 爪转 转砖
    st.chat_message("assistant").write(ai_response)
    st.session_state.messages.append({"role": "model", "parts": [ai_response]})
